{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jtxyjT4_0Zzo",
    "outputId": "2b784c73-b1d6-41eb-c454-eed8037b9a67",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting numpy<2,>=1.21 (from matplotlib)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "mizani 0.13.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "plotnine 0.14.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\n",
      "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed numpy-1.26.4\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.10/dist-packages (1.7.3)\n",
      "Collecting numpy<1.23.0,>=1.16.5 (from scipy==1.7.3)\n",
      "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
      "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
      "astropy 6.1.6 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n",
      "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
      "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
      "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "mizani 0.13.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
      "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "plotnine 0.14.1 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "plotnine 0.14.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\n",
      "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed numpy-1.22.4\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       },
       "id": "84821f8637bb4e768440e69fa5233ba1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Import successful.\n",
      "Model loaded from disk.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-27-f34f57e504f3>:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "<ipython-input-27-f34f57e504f3>:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cnn2.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Without Defense:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'attack_params' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-f34f57e504f3>\u001B[0m in \u001B[0;36m<cell line: 119>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"With Defense:\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m     \u001B[0mF1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFGSM\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m### or cuda\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m     \u001B[0mAdvExArray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0myy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mattack_params\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'FGSM_MNIST'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m     \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAdvExArray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'attack_params' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install torch torchvision pillow\n",
    "!pip install scipy==1.7.3\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "sys.path.append('DeepRobust/build/lib')\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from deeprobust.image.attack.fgsm import FGSM\n",
    "import mnist_model as mnist_model\n",
    "importlib.reload(sys.modules['mnist_model'])\n",
    "from mnist_model import Net\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "try:\n",
    "    from deeprobust.image import optimizer\n",
    "    from deeprobust.image.defense.fgsmtraining import FGSMtraining\n",
    "    import deeprobust.image.netmodels.CNN as CNN\n",
    "    print(\"Import successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Import failed: {e}\")\n",
    "import torch\n",
    "import deeprobust.image.netmodels.train_model as trainmodel\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "# Define the path to store the dataset\n",
    "dataset_path = '../data'\n",
    "model_save_path = 'trained_models/trained_fgsm_model.pth'\n",
    "\n",
    "cnn = mnist_model.Net()\n",
    "W = Variable(torch.randn(4, 3), requires_grad=True)\n",
    "b = Variable(torch.randn(3), requires_grad=True)\n",
    "\n",
    "optimizer = optim.Adam([W, b])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if os.path.exists(os.path.join(os.getcwd(), 'trained_models', 'mnist_cnn.pt')):\n",
    "    state_dict = torch.load(\n",
    "        \"trained_models/mnist_cnn.pt\")\n",
    "    cnn.load_state_dict(state_dict)\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Net().to(device)\n",
    "\n",
    "    # Set training parameters\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 1\n",
    "    lr = 1.0\n",
    "    gamma = 0.7\n",
    "    log_interval = 10\n",
    "    dry_run = False\n",
    "\n",
    "    # Define datasets and loaders\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True, transform=transform),\n",
    "        batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transform),\n",
    "        batch_size=test_batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Training setup\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    # Train and test\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        mnist_model.train(log_interval, dry_run, model, device, train_loader, optimizer, epoch)  # Pass None for args\n",
    "        mnist_model.test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), \"trained_models/mnist_cnn.pt\")\n",
    "    state_dict = torch.load(\n",
    "        \"trained_models/mnist_cnn.pt\")\n",
    "    cnn.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "if os.path.exists(model_save_path):\n",
    "    # Load the pre-trained model weights\n",
    "    cnn2 = mnist_model.Net()\n",
    "    cnn2.load_state_dict(torch.load(model_save_path))\n",
    "    print(\"Model loaded from disk.\")\n",
    "    train_loader, test_loader = trainmodel.feed_dataset('MNIST', dataset_path)\n",
    "else:\n",
    "    # Load the dataset\n",
    "    train_loader, test_loader = trainmodel.feed_dataset('MNIST', dataset_path)\n",
    "\n",
    "    # FGSM training\n",
    "    f = FGSMtraining(cnn, 'cuda')\n",
    "    defense_model = f.generate(train_loader,test_loader,epoch_num=20)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(defense_model.state_dict(), model_save_path)\n",
    "    cnn2 = mnist_model.Net()\n",
    "    cnn2.load_state_dict(f.model.state_dict())\n",
    "    cnn2 = cnn2.to(device=device)\n",
    "    print(\"Model trained and saved to disk.\")\n",
    "\n",
    "xx = datasets.MNIST(dataset_path, download=True).data[998:999].to('cpu')\n",
    "xx = xx.unsqueeze_(1).float() / 255\n",
    "yy = datasets.MNIST(dataset_path, download=True).targets[998:999].to('cpu')\n",
    "\n",
    "for i, model in enumerate([cnn, cnn2]):\n",
    "    if i == 0:\n",
    "        print(\"Without Defense:\")\n",
    "    else:\n",
    "        print(\"With Defense:\")\n",
    "    F1 = FGSM(model, device=device)  ### or cuda\n",
    "    AdvExArray = F1.generate(xx, yy, **attack_params['FGSM_MNIST'])\n",
    "\n",
    "    plt.imshow(AdvExArray.detach()[0].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "    predict0 = model(xx)\n",
    "    predict0 = predict0.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    predict1 = model(AdvExArray)\n",
    "    predict1 = predict1.argmax(dim=1, keepdim=True)\n",
    "    print(\"original prediction:\")\n",
    "    print(predict0.item())\n",
    "\n",
    "    print(\"attack prediction:\")\n",
    "    print(predict1.item())\n",
    "\n",
    "    print(\"actual value:\")\n",
    "    print(yy.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOOga7e656wN",
    "outputId": "4481f835-73ed-4fae-918a-4d25e532a16d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  }
 ]
}